---
title: "MODEL 2 NEURAL NETWORK-BASED CLASSIFICATION MODEL"
author: "JUDISMA SALI"
date: "2022-12-16"
output:
  pdf_document: default
  html_document: default
---
# Creating a Neural Network-Based Classification Model.
 
 Note that we used the reprocessed data of radiomics_complete.csv (*RAD. NORMAL DATA.CSV*) in performing neural network-based classification model
 
# LOAD PACKAGES

```{r}
# Helper packages

library(dplyr)         # for data wrangling
library(tidyverse)     # for filtering 
library(readr)         # load dataset
library(rsample)       # for creating validation splits
library(bestNormalize) # for normalizing the dataset

# Modeling packages

library(keras)         # for fitting DNNs
library(tfruns)        # for additional grid search & model training functions
library(tensorflow)

# Modeling helper package

library(tfestimators)  # provides grid search & model training interface

```

# LOAD THE REPROCESSED DATASET

Radiomics Dataset 197 Rows (Observations) of 431 Columns (Variables)
Failure.binary: binary property to predict

```{r}
radiomicsdt <- read_csv("RAD. NORMAL DATA.CSV")
View(radiomicsdt)
head(radiomicsdt)
```

# CHECKING FOR NULL AND MISSING VALUES

 The result for checking null and missing values is *0* using *sum(is.n())*. Thus, there is no null and missing values.

```{r}
sum(is.na(radiomicsdt))
```

# SPLITTING DATASET INTO TRAINING (0.8) AND TESTING (0.2)

```{r}
radiomicsdt<-radiomicsdt %>%
  mutate(Failure.binary=ifelse(Failure.binary== "No",0,1))
radiomicsdt=radiomicsdt[,-1]

set.seed(123)
split = initial_split(radiomicsdt,prop = 0.8 ,strata = "Failure.binary")
churn_train <- training(split)
churn_test  <- testing(split)

X_train <- churn_train[,-c(1,2)]%>%as.matrix.data.frame()
X_test <- churn_test[,-c(1,2)]%>%as.matrix.data.frame()
y_train <- churn_train$Failure.binary
y_test <- churn_test$Failure.binary
```

# RESHAPING DATASET
```{r}
X_train <- array_reshape(X_train, c(nrow(X_train), ncol(X_train)))
X_train <- X_train 

X_test <- array_reshape(X_test, c(nrow(X_test), ncol(X_test)))
X_test <- X_test 

y_train <- to_categorical(y_train, num_classes = 2)
y_test <- to_categorical(y_test, num_classes = 2)
```

The keras package allows us to develop our network with a layering approach. First, we initiated our sequential feedforward DNN architecture with *keras_model_sequential()* and then added some dense layers.Hence, we created five hidden layers with 256, 128, 128, 64 and 64 neurons, we added the *sigmoid* activation function. Followed by an output layer with 2 nodes and specified activation = *softmax*.

# BACKPROPAGATION COMPILER APPROACH

To perform backpropagation we need two things: An objective function; An optimizer.
First, we established an objective (loss) function to measure performance. For classification problems it is commonly binary and multi-categorical cross
entropy. On each forward pass the DNN will measure its performance based on the loss function chosen. To incorporate the backpropagation piece of our DNN we include compile() in our code sequence. In addition to the
optimizer and loss function arguments, we can also identify one or more metrics in addition to our loss function to
track and report
```{r}
model <- keras_model_sequential() %>%
  layer_dense(units = 256, activation = "sigmoid", input_shape = c(ncol(X_train))) %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 128, activation = "sigmoid") %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 128, activation = "sigmoid") %>%
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 64, activation = "sigmoid") %>% 
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 64, activation = "sigmoid") %>% 
  layer_dropout(rate = 0.2) %>%
  layer_dense(units = 2, activation = "softmax")%>%
 compile(
    loss = "categorical_crossentropy",
    optimizer = optimizer_rmsprop(),
    metrics = c("accuracy")
  )
```

# MODEL COMPILER APPROACH

```{r}
 model %>% compile(
  loss = "categorical_crossentropy",
  optimizer = optimizer_adam(),
  metrics = c("accuracy")
)
```


# TRAINING THE MODEL

To do so we feed our model into a fit() function along with our training data. We also provide a few other arguments that are worth mentioning: EPOCH = 10, BATCH SIZE = 128 AND VALIDATION SPLIT = 0.15

An epoch indicates how many times the algorithm views the entire dataset. Therefore, an epoch has ended whenever the algorithm has viewed all of the samples in the data set. Since a single epoch would be too large to transmit to the computer all at once, we divide it in several smaller batches.

```{r}
trainm <- model %>% 
  fit(X_train, y_train, epochs = 10, batch_size = 128, validation_split = 0.15)

trainm

plot(trainm)
```

# EVALUATE THE TRAINED MODEL USING THE TESTING DATASET. 

```{r}
model %>%
  evaluate(X_test, y_test)
dim(X_test)
dim(y_test)
```

# MODEL PREDICTION USING THE TESTING DATASET

```{r}
model   %>% predict(X_test) %>% `>`(0.8) %>% k_cast("int32")
```
